{"attributes":{"kind":"function","backlinks":[{"tag":"sourcefile","title":"Surrogates/src/Surrogates.jl","docid":"sourcefiles/Surrogates/src/Surrogates.jl"},{"tag":"sourcefile","title":"Surrogates/src/Optimization.jl","docid":"sourcefiles/Surrogates/src/Optimization.jl"}],"methods":[{"line":1528,"file":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/src/Optimization.jl","method_id":"Surrogates.surrogate_optimize_1","symbol_id":"Surrogates.surrogate_optimize","filedoc":"sourcefiles/Surrogates/src/Optimization.jl","signature":"surrogate_optimize(obj, rtea::Surrogates.RTEA, lb::Number, ub::Number, surrRTEA::Surrogates.AbstractSurrogate, sample_type::QuasiMonteCarlo.SamplingAlgorithm; maxiters, n_new_look)"},{"line":1633,"file":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/src/Optimization.jl","method_id":"Surrogates.surrogate_optimize_2","symbol_id":"Surrogates.surrogate_optimize","filedoc":"sourcefiles/Surrogates/src/Optimization.jl","signature":"surrogate_optimize(obj, rtea::Surrogates.RTEA, lb, ub, surrRTEAND::Surrogates.AbstractSurrogate, sample_type::QuasiMonteCarlo.SamplingAlgorithm; maxiters, n_new_look)"},{"line":229,"file":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/src/Optimization.jl","method_id":"Surrogates.surrogate_optimize_3","symbol_id":"Surrogates.surrogate_optimize","filedoc":"sourcefiles/Surrogates/src/Optimization.jl","signature":"surrogate_optimize(obj::Function, ::Surrogates.SRBF, lb::Number, ub::Number, surr::Surrogates.AbstractSurrogate, sample_type::QuasiMonteCarlo.SamplingAlgorithm; maxiters, num_new_samples)"},{"line":77,"file":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/src/Optimization.jl","method_id":"Surrogates.surrogate_optimize_4","symbol_id":"Surrogates.surrogate_optimize","filedoc":"sourcefiles/Surrogates/src/Optimization.jl","signature":"surrogate_optimize(obj::Function, ::Surrogates.SRBF, lb, ub, surr::Surrogates.AbstractSurrogate, sample_type::QuasiMonteCarlo.SamplingAlgorithm; maxiters, num_new_samples)"},{"line":372,"file":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/src/Optimization.jl","method_id":"Surrogates.surrogate_optimize_5","symbol_id":"Surrogates.surrogate_optimize","filedoc":"sourcefiles/Surrogates/src/Optimization.jl","signature":"surrogate_optimize(obj::Function, ::Surrogates.LCBS, lb::Number, ub::Number, krig, sample_type::QuasiMonteCarlo.SamplingAlgorithm; maxiters, num_new_samples, k)"},{"line":431,"file":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/src/Optimization.jl","method_id":"Surrogates.surrogate_optimize_6","symbol_id":"Surrogates.surrogate_optimize","filedoc":"sourcefiles/Surrogates/src/Optimization.jl","signature":"surrogate_optimize(obj::Function, ::Surrogates.LCBS, lb, ub, krig, sample_type::QuasiMonteCarlo.SamplingAlgorithm; maxiters, num_new_samples, k)"},{"line":489,"file":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/src/Optimization.jl","method_id":"Surrogates.surrogate_optimize_7","symbol_id":"Surrogates.surrogate_optimize","filedoc":"sourcefiles/Surrogates/src/Optimization.jl","signature":"surrogate_optimize(obj::Function, ::Surrogates.EI, lb::Number, ub::Number, krig, sample_type::QuasiMonteCarlo.SamplingAlgorithm; maxiters, num_new_samples)"},{"line":703,"file":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/src/Optimization.jl","method_id":"Surrogates.surrogate_optimize_8","symbol_id":"Surrogates.surrogate_optimize","filedoc":"sourcefiles/Surrogates/src/Optimization.jl","signature":"surrogate_optimize(obj::Function, ::Surrogates.DYCORS, lb::Number, ub::Number, surr1::Surrogates.AbstractSurrogate, sample_type::QuasiMonteCarlo.SamplingAlgorithm; maxiters, num_new_samples)"},{"line":824,"file":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/src/Optimization.jl","method_id":"Surrogates.surrogate_optimize_9","symbol_id":"Surrogates.surrogate_optimize","filedoc":"sourcefiles/Surrogates/src/Optimization.jl","signature":"surrogate_optimize(obj::Function, ::Surrogates.DYCORS, lb, ub, surrn::Surrogates.AbstractSurrogate, sample_type::QuasiMonteCarlo.SamplingAlgorithm; maxiters, num_new_samples)"},{"line":1008,"file":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/src/Optimization.jl","method_id":"Surrogates.surrogate_optimize_10","symbol_id":"Surrogates.surrogate_optimize","filedoc":"sourcefiles/Surrogates/src/Optimization.jl","signature":"surrogate_optimize(obj::Function, sop1::Surrogates.SOP, lb::Number, ub::Number, surrSOP::Surrogates.AbstractSurrogate, sample_type::QuasiMonteCarlo.SamplingAlgorithm; maxiters, num_new_samples)"},{"line":1256,"file":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/src/Optimization.jl","method_id":"Surrogates.surrogate_optimize_11","symbol_id":"Surrogates.surrogate_optimize","filedoc":"sourcefiles/Surrogates/src/Optimization.jl","signature":"surrogate_optimize(obj::Function, sopd::Surrogates.SOP, lb, ub, surrSOPD::Surrogates.AbstractSurrogate, sample_type::QuasiMonteCarlo.SamplingAlgorithm; maxiters, num_new_samples)"},{"line":1450,"file":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/src/Optimization.jl","method_id":"Surrogates.surrogate_optimize_12","symbol_id":"Surrogates.surrogate_optimize","filedoc":"sourcefiles/Surrogates/src/Optimization.jl","signature":"surrogate_optimize(obj::Function, sbm::Surrogates.SMB, lb::Number, ub::Number, surrSMB::Surrogates.AbstractSurrogate, sample_type::QuasiMonteCarlo.SamplingAlgorithm; maxiters, n_new_look)"},{"line":1488,"file":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/src/Optimization.jl","method_id":"Surrogates.surrogate_optimize_13","symbol_id":"Surrogates.surrogate_optimize","filedoc":"sourcefiles/Surrogates/src/Optimization.jl","signature":"surrogate_optimize(obj::Function, smb::Surrogates.SMB, lb, ub, surrSMBND::Surrogates.AbstractSurrogate, sample_type::QuasiMonteCarlo.SamplingAlgorithm; maxiters, n_new_look)"},{"line":1739,"file":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/src/Optimization.jl","method_id":"Surrogates.surrogate_optimize_14","symbol_id":"Surrogates.surrogate_optimize","filedoc":"sourcefiles/Surrogates/src/Optimization.jl","signature":"surrogate_optimize(obj::Function, ::Surrogates.EI, lb, ub, krig, sample_type::QuasiMonteCarlo.SectionSample; maxiters, num_new_samples)"},{"line":562,"file":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/src/Optimization.jl","method_id":"Surrogates.surrogate_optimize_15","symbol_id":"Surrogates.surrogate_optimize","filedoc":"sourcefiles/Surrogates/src/Optimization.jl","signature":"surrogate_optimize(obj::Function, ::Surrogates.EI, lb, ub, krig, sample_type::QuasiMonteCarlo.SamplingAlgorithm; maxiters, num_new_samples)"}],"name":"surrogate_optimize","title":"surrogate_optimize","symbol_id":"Surrogates.surrogate_optimize","public":true,"module_id":"Surrogates"},"tag":"documentation","children":[{"attributes":{},"tag":"md","children":[{"attributes":{},"tag":"p","children":["The main idea is to pick the new evaluations from a set of candidate points where each candidate point is generated as an N(0, sigma^2) distributed perturbation from the current best solution. The value of sigma is modified based on progress and follows the same logic as in many trust region methods: we increase sigma if we make a lot of progress (the surrogate is accurate) and decrease sigma when we arenâ€™t able to make progress (the surrogate model is inaccurate). More details about how sigma is updated is given in the original papers."],"type":"node"},{"attributes":{},"tag":"p","children":["After generating the candidate points, we predict their objective function value and compute the minimum distance to the previously evaluated point. Let the candidate points be denoted by C and let the function value predictions be s(x",{"attributes":{},"tag":"backslash","children":[{"mimes":{"text/plain":"Any[]"},"type":"leaf"},{"mimes":{"text/plain":"Dict{Symbol, String}()"},"type":"leaf"}],"type":"node"},"_i) and the distance values be d(x",{"attributes":{},"tag":"backslash","children":[{"mimes":{"text/plain":"Any[]"},"type":"leaf"},{"mimes":{"text/plain":"Dict{Symbol, String}()"},"type":"leaf"}],"type":"node"},"_i), both rescaled through a linear transformation to the interval [0,1]. This is done to put the values on the same scale. The next point selected for evaluation is the candidate point x that minimizes the weighted-distance merit function:"],"type":"node"},{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"math","children":["merit(x) = ws(x) + (1-w)(1-d(x))"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["where ",{"attributes":{},"tag":"math","children":["0 \\leq w \\leq 1"],"type":"node"},". That is, we want a small function value prediction and a large minimum distance from the previously evaluated points. The weight w is commonly cycled between a few values to achieve both exploitation and exploration. When w is close to zero, we do pure exploration, while w close to 1 corresponds to exploitation."],"type":"node"},{"attributes":{},"tag":"hr","children":[{"mimes":{"text/plain":"Any[]"},"type":"leaf"},{"mimes":{"text/plain":"Dict{Symbol, String}()"},"type":"leaf"}],"type":"node"},{"attributes":{},"tag":"p","children":["SRBF 1D: surrogate_optimize(obj::Function,::SRBF,lb::Number,ub::Number,surr::AbstractSurrogate,sample_type::SamplingAlgorithm;maxiters=100,num_new_samples=100)"],"type":"node"},{"attributes":{},"tag":"hr","children":[{"mimes":{"text/plain":"Any[]"},"type":"leaf"},{"mimes":{"text/plain":"Dict{Symbol, String}()"},"type":"leaf"}],"type":"node"},{"attributes":{},"tag":"p","children":["This is an implementation of Lower Confidence Bound (LCB), a popular acquisition function in Bayesian optimization. Under a Gaussian process (GP) prior, the goal is to minimize: ",{"attributes":{},"tag":"math","children":["LCB(x) := E[x] - k * \\sqrt{(V[x])}"],"type":"node"}," default value ",{"attributes":{},"tag":"math","children":["k = 2"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"hr","children":[{"mimes":{"text/plain":"Any[]"},"type":"leaf"},{"mimes":{"text/plain":"Dict{Symbol, String}()"},"type":"leaf"}],"type":"node"},{"attributes":{},"tag":"p","children":["This is an implementation of Lower Confidence Bound (LCB), a popular acquisition function in Bayesian optimization. Under a Gaussian process (GP) prior, the goal is to minimize:"],"type":"node"},{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"math","children":["LCB(x) := E[x] - k * \\sqrt{(V[x])}"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["default value ",{"attributes":{},"tag":"math","children":["k = 2"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"hr","children":[{"mimes":{"text/plain":"Any[]"},"type":"leaf"},{"mimes":{"text/plain":"Dict{Symbol, String}()"},"type":"leaf"}],"type":"node"},{"attributes":{},"tag":"p","children":["Expected improvement method 1D"],"type":"node"},{"attributes":{},"tag":"hr","children":[{"mimes":{"text/plain":"Any[]"},"type":"leaf"},{"mimes":{"text/plain":"Dict{Symbol, String}()"},"type":"leaf"}],"type":"node"},{"attributes":{},"tag":"p","children":["This is an implementation of Expected Improvement (EI), arguably the most popular acquisition function in Bayesian optimization. Under a Gaussian process (GP) prior, the goal is to maximize expected improvement:"],"type":"node"},{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"math","children":["EI(x) := E[max(f_{best}-f(x),0)"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"hr","children":[{"mimes":{"text/plain":"Any[]"},"type":"leaf"},{"mimes":{"text/plain":"Dict{Symbol, String}()"},"type":"leaf"}],"type":"node"},{"attributes":{},"tag":"p","children":["surrogate_optimize(obj::Function,::DYCORS,lb::Number,ub::Number,surr1::AbstractSurrogate,sample_type::SamplingAlgorithm;maxiters=100,num_new_samples=100)"],"type":"node"},{"attributes":{},"tag":"p","children":["DYCORS optimization method in 1D, following closely: Combining radial basis function surrogates and dynamic coordinate search in high-dimensional expensive black-box optimization\"."],"type":"node"},{"attributes":{},"tag":"hr","children":[{"mimes":{"text/plain":"Any[]"},"type":"leaf"},{"mimes":{"text/plain":"Dict{Symbol, String}()"},"type":"leaf"}],"type":"node"},{"attributes":{"lang":""},"tag":"codeblock","children":["  surrogate_optimize(obj::Function,::DYCORS,lb::Number,ub::Number,surr1::AbstractSurrogate,sample_type::SamplingAlgorithm;maxiters=100,num_new_samples=100)\n"],"type":"node"},{"attributes":{},"tag":"p","children":["This is an implementation of the DYCORS strategy by Regis and Shoemaker: Rommel G Regis and Christine A Shoemaker. Combining radial basis function surrogates and dynamic coordinate search in high-dimensional expensive black-box optimization. Engineering Optimization, 45(5): 529â€“555, 2013. This is an extension of the SRBF strategy that changes how the candidate points are generated. The main idea is that many objective functions depend only on a few directions so it may be advantageous to perturb only a few directions. In particular, we use a perturbation probability to perturb a given coordinate and decrease this probability after each function evaluation so fewer coordinates are perturbed later in the optimization."],"type":"node"},{"attributes":{},"tag":"hr","children":[{"mimes":{"text/plain":"Any[]"},"type":"leaf"},{"mimes":{"text/plain":"Dict{Symbol, String}()"},"type":"leaf"}],"type":"node"},{"attributes":{},"tag":"p","children":["surrogate_optimize(obj::Function,::SOP,lb::Number,ub::Number,surr::AbstractSurrogate,sample_type::SamplingAlgorithm;maxiters=100,num_new_samples=100)"],"type":"node"},{"attributes":{},"tag":"p","children":["SOP Surrogate optimization method, following closely the following papers:"],"type":"node"},{"attributes":{"lang":""},"tag":"codeblock","children":["- SOP: parallel surrogate global optimization with Pareto center selection for computationally expensive single objective problems by Tipaluck Krityakierne\n- Multiobjective Optimization Using Evolutionary Algorithms by Kalyan Deb\n"],"type":"node"},{"attributes":{},"tag":"p","children":["#Suggested number of new_samples = min(500*d,5000)"],"type":"node"}],"type":"node"}],"type":"node"}