{"attributes":{"kind":"struct","backlinks":[{"tag":"document","title":"Neural Ordinary Differential Equations with Flux.train!","docid":"DiffEqSensitivity/neural_ode/neural_ode_flux.md"},{"tag":"document","title":"NLopt.jl","docid":"Optimization/optimization_packages/nlopt.md"},{"tag":"document","title":"Neural ODEs on GPUs","docid":"DiffEqSensitivity/neural_ode/GPUs.md"},{"tag":"sourcefile","title":"Optimization/src/Optimization.jl","docid":"sourcefiles/Optimization/src/Optimization.jl"},{"tag":"document","title":"Basic usage","docid":"Optimization/tutorials/intro.md"},{"tag":"document","title":"Strategies to Avoid Local Minima","docid":"DiffEqSensitivity/training_tips/local_minima.md"},{"tag":"sourcefile","title":"Optimization/src/function/tracker.jl","docid":"sourcefiles/Optimization/src/function/tracker.jl"},{"tag":"document","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","docid":"DiffEqSensitivity/neural_ode/neural_ode_galacticoptim.md"},{"tag":"document","title":"Parameter Estimation on Highly Stiff Systems","docid":"DiffEqSensitivity/ode_fitting/stiff_ode_fit.md"},{"tag":"documentation","title":"AutoZygote","docid":"references/Optimization.AutoZygote"},{"tag":"sourcefile","title":"SciMLBase/src/problems/basic_problems.jl","docid":"sourcefiles/SciMLBase/src/problems/basic_problems.jl"},{"tag":"document","title":"GCMAES.jl","docid":"Optimization/optimization_packages/gcmaes.md"},{"tag":"sourcefile","title":"Optimization/src/function/zygote.jl","docid":"sourcefiles/Optimization/src/function/zygote.jl"},{"tag":"document","title":"Evolutionary.jl","docid":"Optimization/optimization_packages/evolutionary.md"},{"tag":"sourcefile","title":"SciMLBase/src/scimlfunctions.jl","docid":"sourcefiles/SciMLBase/src/scimlfunctions.jl"},{"tag":"document","title":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","docid":"DiffEqSensitivity/ode_fitting/second_order_adjoints.md"},{"tag":"sourcefile","title":"SciMLBase/src/SciMLBase.jl","docid":"sourcefiles/SciMLBase/src/SciMLBase.jl"},{"tag":"document","title":"Rosenbrock function examples","docid":"Optimization/tutorials/rosenbrock.md"},{"tag":"document","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","docid":"DiffEqFlux/examples/tensor_layer.md"},{"tag":"document","title":"QuadDIRECT.jl","docid":"Optimization/optimization_packages/quaddirect.md"},{"tag":"document","title":"CMAEvolutionStrategy.jl","docid":"Optimization/optimization_packages/cmaevolutionstrategy.md"},{"tag":"document","title":"[Solving Optimal Control Problems with Universal Differential Equations]( optcontrol)","docid":"DiffEqSensitivity/optimal_control/optimal_control.md"},{"tag":"document","title":"Neural Ordinary Differential Equations","docid":"DiffEqFlux/examples/neural_ode.md"},{"tag":"document","title":"Nonconvex.jl","docid":"Optimization/optimization_packages/nonconvex.md"},{"tag":"document","title":"Prediction error method (PEM)","docid":"DiffEqSensitivity/ode_fitting/prediction_error_method.md"},{"tag":"documentation","title":"AutoFiniteDiff","docid":"references/Optimization.AutoFiniteDiff"},{"tag":"document","title":"[Optim.jl]( optim)","docid":"Optimization/optimization_packages/optim.md"},{"tag":"sourcefile","title":"Optimization/src/function/finitediff.jl","docid":"sourcefiles/Optimization/src/function/finitediff.jl"},{"tag":"documentation","title":"AutoTracker","docid":"references/Optimization.AutoTracker"},{"tag":"document","title":"Metaheuristics.jl","docid":"Optimization/optimization_packages/metaheuristics.md"},{"tag":"sourcefile","title":"DiffEqFlux/src/train.jl","docid":"sourcefiles/DiffEqFlux/src/train.jl"},{"tag":"document","title":"Handling Divergent and Unstable Trajectories","docid":"DiffEqSensitivity/training_tips/divergence.md"},{"tag":"sourcefile","title":"Optimization/src/function/reversediff.jl","docid":"sourcefiles/Optimization/src/function/reversediff.jl"},{"tag":"documentation","title":"AutoForwardDiff","docid":"references/Optimization.AutoForwardDiff"},{"tag":"documentation","title":"AutoReverseDiff","docid":"references/Optimization.AutoReverseDiff"},{"tag":"document","title":"Multiple Shooting","docid":"DiffEqFlux/examples/multiple_shooting.md"},{"tag":"document","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","docid":"DiffEqSensitivity/ode_fitting/data_parallel.md"},{"tag":"document","title":"Smoothed Collocation for Fast Two-Stage Training","docid":"DiffEqFlux/examples/collocation.md"},{"tag":"document","title":"Minibatch examples","docid":"Optimization/tutorials/minibatch.md"},{"tag":"sourcefile","title":"NeuralPDE/src/neural_adapter.jl","docid":"sourcefiles/NeuralPDE/src/neural_adapter.jl"},{"tag":"document","title":"Neural Second Order Ordinary Differential Equation","docid":"DiffEqSensitivity/ode_fitting/second_order_neural.md"},{"tag":"document","title":"NOMAD.jl","docid":"Optimization/optimization_packages/nomad.md"},{"tag":"sourcefile","title":"Optimization/src/function/function.jl","docid":"sourcefiles/Optimization/src/function/function.jl"},{"tag":"document","title":"Universal Differential Equations for Neural Feedback Control","docid":"DiffEqSensitivity/optimal_control/feedback_control.md"},{"tag":"document","title":"Bouncing Ball Hybrid ODE Optimization","docid":"DiffEqSensitivity/hybrid_jump_fitting/bouncing_ball.md"},{"tag":"document","title":"Systems of PDEs","docid":"NeuralPDE/pinn/system.md"},{"tag":"document","title":"Handling Exogenous Input Signals","docid":"DiffEqSensitivity/ode_fitting/exogenous_input.md"},{"tag":"document","title":"Delay Differential Equations","docid":"DiffEqSensitivity/dde_fitting/delay_diffeq.md"},{"tag":"sourcefile","title":"NeuralPDE/src/pinns_pde_solve.jl","docid":"sourcefiles/NeuralPDE/src/pinns_pde_solve.jl"},{"tag":"sourcefile","title":"Optimization/src/function/mtk.jl","docid":"sourcefiles/Optimization/src/function/mtk.jl"},{"tag":"document","title":"BlackBoxOptim.jl","docid":"Optimization/optimization_packages/blackboxoptim.md"},{"tag":"document","title":"Neural Stochastic Differential Equations","docid":"DiffEqSensitivity/sde_fitting/neural_sde.md"},{"tag":"document","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","docid":"DiffEqSensitivity/dae_fitting/physical_constraints.md"},{"tag":"document","title":"1-D Burgers' Equation With Low-Level API","docid":"NeuralPDE/pinn/low_level.md"},{"tag":"sourcefile","title":"Optimization/src/function/forwarddiff.jl","docid":"sourcefiles/Optimization/src/function/forwarddiff.jl"},{"tag":"document","title":"MultiStartOptimization.jl","docid":"Optimization/optimization_packages/multistartoptimization.md"},{"tag":"document","title":"Partial Differential Equation (PDE) Constrained Optimization","docid":"DiffEqSensitivity/pde_fitting/pde_constrained.md"},{"tag":"document","title":"Optimization of Ordinary Differential Equations","docid":"DiffEqSensitivity/ode_fitting/optimization_ode.md"},{"tag":"document","title":"MathOptInterface.jl","docid":"Optimization/optimization_packages/mathoptinterface.md"},{"tag":"document","title":"Simultaneous Fitting of Multiple Neural Networks","docid":"DiffEqSensitivity/training_tips/multiple_nn.md"},{"tag":"sourcefile","title":"ModelingToolkit/src/systems/optimization/optimizationsystem.jl","docid":"sourcefiles/ModelingToolkit/src/systems/optimization/optimizationsystem.jl"},{"tag":"document","title":"Optimization of Stochastic Differential Equations","docid":"DiffEqSensitivity/sde_fitting/optimization_sde.md"}],"methods":[{"line":2537,"file":"/Users/lorenz/.julia/packages/SciMLBase/dYFnI/src/scimlfunctions.jl","method_id":"SciMLBase.OptimizationFunction_1","symbol_id":"SciMLBase.OptimizationFunction","filedoc":"sourcefiles/SciMLBase/src/scimlfunctions.jl","signature":"OptimizationFunction(args...; kwargs...)"}],"name":"OptimizationFunction","title":"OptimizationFunction","symbol_id":"SciMLBase.OptimizationFunction","public":true,"module_id":"SciMLBase"},"tag":"documentation","children":[{"attributes":{},"tag":"md","children":[{"attributes":{},"tag":"p","children":["OptimizationFunction <: AbstractOptimizationFunction"],"type":"node"},{"attributes":{},"tag":"p","children":["A representation of an optimization of an objective function ",{"attributes":{},"tag":"code","children":["f"],"type":"node"},", defined by:"],"type":"node"},{"attributes":{},"tag":"mathblock","children":["min_{u} f(u,p)"],"type":"node"},{"attributes":{},"tag":"p","children":["and all of its related functions, such as the gradient of ",{"attributes":{},"tag":"code","children":["f"],"type":"node"},", its Hessian, and more. For all cases, ",{"attributes":{},"tag":"code","children":["u"],"type":"node"}," is the state and ",{"attributes":{},"tag":"code","children":["p"],"type":"node"}," are the parameters."],"type":"node"},{"attributes":{},"tag":"h2","children":["Constructor"],"type":"node"},{"attributes":{},"tag":"p","children":["OptimizationFunction(f,adtype::AbstractADType=NoAD(); grad=nothing,hess=nothing,hv=nothing, cons=nothing, cons_j=nothing,cons_h=nothing, hess_prototype=nothing,cons_jac_prototype=nothing, cons_hess_prototype = nothing, syms = nothing, hess_colorvec = nothing, cons_jac_colorvec = nothing, cons_hess_colorvec = nothing)"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["adtype"],"type":"node"},": see the section \"Defining Optimization Functions via AD\""],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["grad(G,u,p)"],"type":"node"}," or ",{"attributes":{},"tag":"code","children":["G=grad(u,p)"],"type":"node"},": the gradient of ",{"attributes":{},"tag":"code","children":["f"],"type":"node"}," with respect to ",{"attributes":{},"tag":"code","children":["u"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["hess(H,u,p)"],"type":"node"}," or ",{"attributes":{},"tag":"code","children":["H=hess(u,p)"],"type":"node"},": the Hessian of ",{"attributes":{},"tag":"code","children":["f"],"type":"node"}," with respect to ",{"attributes":{},"tag":"code","children":["u"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["hv(Hv,u,v,p)"],"type":"node"}," or ",{"attributes":{},"tag":"code","children":["Hv=hv(u,v,p)"],"type":"node"},": the Hessian-vector product ",{"attributes":{},"tag":"math","children":["rac{d^2 f}{du^2} v"],"type":"node"},"."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["cons(res,x,p)"],"type":"node"}," or ",{"attributes":{},"tag":"code","children":["res=cons(x,p)"],"type":"node"},": the equality constraints vector, where the constraints are satisfied when ",{"attributes":{},"tag":"code","children":["res = 0"],"type":"node"},"."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["cons_j(res,x,p)"],"type":"node"}," or ",{"attributes":{},"tag":"code","children":["res=cons_j(x,p)"],"type":"node"},": the Jacobian of the equality constraints."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["cons_h(res,x,p)"],"type":"node"}," or ",{"attributes":{},"tag":"code","children":["res=cons_h(x,p)"],"type":"node"},": the Hessian of the equality constratins, provided as and array of Hessians with ",{"attributes":{},"tag":"code","children":["res[i]"],"type":"node"}," being the Hessian with respect to the ",{"attributes":{},"tag":"code","children":["i"],"type":"node"},"th output on ",{"attributes":{},"tag":"code","children":["cons"],"type":"node"},"."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["paramjac(pJ,u,p)"],"type":"node"},": returns the parameter Jacobian ",{"attributes":{},"tag":"math","children":["rac{df}{dp}"],"type":"node"},"."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["hess_prototype"],"type":"node"},": a prototype matrix matching the type that matches the Hessian. For example, if the Hessian is tridiagonal, then an appropriately sized ",{"attributes":{},"tag":"code","children":["Hessian"],"type":"node"}," matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a ",{"attributes":{},"tag":"code","children":["SparseMatrixCSC"],"type":"node"}," with a correct sparsity pattern for the Hessian. The default is ",{"attributes":{},"tag":"code","children":["nothing"],"type":"node"},", which means a dense Hessian."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["cons_jac_prototype"],"type":"node"},": a prototype matrix matching the type that matches the constraint Jacobian. The default is ",{"attributes":{},"tag":"code","children":["nothing"],"type":"node"},", which means a dense constraint Jacobian."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["cons_hess_prototype"],"type":"node"},": a prototype matrix matching the type that matches the constraint Hessian. This is defined as an array of matrices, where ",{"attributes":{},"tag":"code","children":["hess[i]"],"type":"node"}," is the Hessian w.r.t. the ",{"attributes":{},"tag":"code","children":["i"],"type":"node"},"th output. For example, if the Hessian is sparse, then ",{"attributes":{},"tag":"code","children":["hess"],"type":"node"}," is a ",{"attributes":{},"tag":"code","children":["Vector{SparseMatrixCSC}"],"type":"node"},". The default is ",{"attributes":{},"tag":"code","children":["nothing"],"type":"node"},", which means a dense constraint Hessian."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["syms"],"type":"node"},": the symbol names for the elements of the equation. This should match ",{"attributes":{},"tag":"code","children":["u0"],"type":"node"}," in size. For example, if ",{"attributes":{},"tag":"code","children":["u = [0.0,1.0]"],"type":"node"}," and ",{"attributes":{},"tag":"code","children":["syms = [:x, :y]"],"type":"node"},", this will apply a canonical naming to the values, allowing ",{"attributes":{},"tag":"code","children":["sol[:x]"],"type":"node"}," in the solution and automatically naming values in plots."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["hess_colorvec"],"type":"node"},": a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the ",{"attributes":{},"tag":"code","children":["hess_prototype"],"type":"node"},". This specializes the Hessian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to ",{"attributes":{},"tag":"code","children":["nothing"],"type":"node"},", which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["cons_jac_colorvec"],"type":"node"},": a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the ",{"attributes":{},"tag":"code","children":["cons_jac_prototype"],"type":"node"},"."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["cons_hess_colorvec"],"type":"node"},": an array of color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the ",{"attributes":{},"tag":"code","children":["cons_hess_prototype"],"type":"node"},"."],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"h2","children":["Defining Optimization Functions Via AD"],"type":"node"},{"attributes":{},"tag":"p","children":["While using the keyword arguments gives the user control over defining all of the possible functions, the simplest way to handle the generation of an ",{"attributes":{},"tag":"code","children":["OptimizationFunction"],"type":"node"}," is by specifying an AD type. By doing so, this will automatically fill in all of the extra functions. For example,"],"type":"node"},{"attributes":{"lang":"julia"},"tag":"codeblock","children":[{"attributes":{},"tag":"julia","children":[{"attributes":{},"tag":"CALL","children":[{"attributes":{"reftype":"symbol","document_id":"references/SciMLBase.OptimizationFunction"},"tag":"reference","children":["OptimizationFunction"],"type":"node"},{"attributes":{},"tag":"LPAREN","children":["("],"type":"node"},{"attributes":{},"tag":"IDENTIFIER","children":["f"],"type":"node"},{"attributes":{},"tag":"COMMA","children":[","],"type":"node"},{"attributes":{},"tag":"CALL","children":[{"attributes":{"reftype":"symbol","document_id":"references/Optimization.AutoZygote"},"tag":"reference","children":["AutoZygote"],"type":"node"},{"attributes":{},"tag":"LPAREN","children":["("],"type":"node"},{"attributes":{},"tag":"RPAREN","children":[")"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"RPAREN","children":[")"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["will use ",{"attributes":{"href":"https://github.com/FluxML/Zygote.jl","title":""},"tag":"a","children":["Zygote.jl"],"type":"node"}," to define all of the necessary functions. Note that if any functions are defined directly, the auto-AD definition does not overwrite the user's choice."],"type":"node"},{"attributes":{},"tag":"p","children":["Each of the AD-based constructors are documented separately via their own dispatches."],"type":"node"},{"attributes":{},"tag":"h2","children":["iip: In-Place vs Out-Of-Place"],"type":"node"},{"attributes":{},"tag":"p","children":["For more details on this argument, see the ODEFunction documentation."],"type":"node"},{"attributes":{},"tag":"h2","children":["recompile: Controlling Compilation and Specialization"],"type":"node"},{"attributes":{},"tag":"p","children":["For more details on this argument, see the ODEFunction documentation."],"type":"node"},{"attributes":{},"tag":"h2","children":["Fields"],"type":"node"},{"attributes":{},"tag":"p","children":["The fields of the OptimizationFunction type directly match the names of the inputs."],"type":"node"}],"type":"node"}],"type":"node"}