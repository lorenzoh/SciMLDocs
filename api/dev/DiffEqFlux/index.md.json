{"attributes":{"backlinks":[],"path":"/Users/lorenz/.julia/packages/DiffEqFlux/JicEk/docs/src/index.md","title":"DiffEqFlux: High Level Pre-Built Architectures for Implicit Deep Learning"},"tag":"document","children":[{"attributes":{},"tag":"md","children":[{"attributes":{},"tag":"h1","children":["DiffEqFlux: High Level Pre-Built Architectures for Implicit Deep Learning"],"type":"node"},{"attributes":{},"tag":"p","children":["DiffEqFlux.jl is an implicit deep learning library built using the SciML ecosystem. It is a high level interface that pulls together all of the tools with heuristics and helper functions to make training such deep implicit layer models fast and easy."],"type":"node"},{"attributes":{"class":"note"},"tag":"admonition","children":[{"attributes":{},"tag":"admonitiontitle","children":["Note"],"type":"node"},{"attributes":{},"tag":"admonitionbody","children":[{"attributes":{},"tag":"p","children":["DiffEqFlux.jl is only for pre-built architectures and utility functions for deep implicit learning, mixing differential equations with machine learning. For details on automatic differentiation of equation solvers and adjoint techniques, and using these methods for doing things like callibrating models to data, nonlinear optimal control, and PDE-constrained optimization, see ",{"attributes":{"href":"https://sensitivity.sciml.ai/dev/","title":""},"tag":"a","children":["SciMLSensitivity.jl"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"h2","children":["Pre-Built Architectures"],"type":"node"},{"attributes":{},"tag":"p","children":["The approach of this package is the easy and efficient training of ",{"attributes":{"href":"https://arxiv.org/abs/2001.04385","title":""},"tag":"a","children":["Universal Differential Equations"],"type":"node"},". DiffEqFlux.jl provides architectures which match the interfaces of machine learning libraries such as ",{"attributes":{"href":"https://fluxml.ai/","title":""},"tag":"a","children":["Flux.jl"],"type":"node"}," and ",{"attributes":{"href":"http://lux.csail.mit.edu/dev/","title":""},"tag":"a","children":["Lux.jl"],"type":"node"}," to make it easy to build continuous-time machine learning layers into larger machine learning applications."],"type":"node"},{"attributes":{},"tag":"p","children":["The following layer functions exist:"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"href":"https://arxiv.org/abs/1806.07366","title":""},"tag":"a","children":["Neural Ordinary Differential Equations (Neural ODEs)"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"href":"https://www.degruyter.com/document/doi/10.1515/sagmb-2020-0025/html","title":""},"tag":"a","children":["Collocation-Based Neural ODEs (Neural ODEs without a solver, by far the fastest way!)"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"href":"https://arxiv.org/abs/2109.06786","title":""},"tag":"a","children":["Multiple Shooting Neural Ordinary Differential Equations"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"href":"https://arxiv.org/abs/1907.07587","title":""},"tag":"a","children":["Neural Stochastic Differential Equations (Neural SDEs)"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"href":"https://arxiv.org/abs/2001.04385","title":""},"tag":"a","children":["Neural Differential-Algebriac Equations (Neural DAEs)"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"href":"https://arxiv.org/abs/2001.04385","title":""},"tag":"a","children":["Neural Delay Differential Equations (Neural DDEs)"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"href":"https://arxiv.org/abs/1904.01681","title":""},"tag":"a","children":["Augmented Neural ODEs"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"href":"https://arxiv.org/abs/1906.01563","title":""},"tag":"a","children":["Hamiltonian Neural Networks (with specialized second order and symplectic integrators)"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"href":"https://arxiv.org/abs/1806.07366","title":""},"tag":"a","children":["Continuous Normalizing Flows (CNF)"],"type":"node"}," and ",{"attributes":{"href":"https://arxiv.org/abs/1810.01367","title":""},"tag":"a","children":["FFJORD"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["Examples of how to build architectures from scratch, with tutorials on things like Graph Neural ODEs, can be found in the ",{"attributes":{"reftype":"document","href":"sensitivity.sciml.ai/dev","title":"","document_id":"DiffEqFlux/sensitivity.sciml.ai/dev"},"tag":"reference","children":["SciMLSensitivity.jl documentation"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"p","children":["WIP:"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Lagrangian Neural Networks"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Galerkin Neural ODEs"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"h2","children":["Citation"],"type":"node"},{"attributes":{},"tag":"p","children":["If you use DiffEqFlux.jl or are influenced by its ideas, please cite:"],"type":"node"},{"attributes":{"lang":""},"tag":"codeblock","children":["@article{rackauckas2020universal,\n  title={Universal differential equations for scientific machine learning},\n  author={Rackauckas, Christopher and Ma, Yingbo and Martensen, Julius and Warner, Collin and Zubov, Kirill and Supekar, Rohit and Skinner, Dominic and Ramadhan, Ali},\n  journal={arXiv preprint arXiv:2001.04385},\n  year={2020}\n}\n"],"type":"node"}],"type":"node"}],"type":"node"}