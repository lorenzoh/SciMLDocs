{"attributes":{"kind":"struct","backlinks":[{"tag":"sourcefile","title":"NeuralPDE/src/pinns_pde_solve.jl","docid":"sourcefiles/NeuralPDE/src/pinns_pde_solve.jl"},{"tag":"sourcefile","title":"NeuralPDE/src/NeuralPDE.jl","docid":"sourcefiles/NeuralPDE/src/NeuralPDE.jl"}],"methods":[{"line":296,"file":"/Users/lorenz/.julia/packages/NeuralPDE/y7uHG/src/pinns_pde_solve.jl","method_id":"NeuralPDE.GradientScaleAdaptiveLoss_1","symbol_id":"NeuralPDE.GradientScaleAdaptiveLoss","filedoc":"sourcefiles/NeuralPDE/src/pinns_pde_solve.jl","signature":"NeuralPDE.GradientScaleAdaptiveLoss(; reweight_every, weight_change_inertia, pde_loss_weights, bc_loss_weights, additional_loss_weights)"},{"line":296,"file":"/Users/lorenz/.julia/packages/NeuralPDE/y7uHG/src/pinns_pde_solve.jl","method_id":"NeuralPDE.GradientScaleAdaptiveLoss_2","symbol_id":"NeuralPDE.GradientScaleAdaptiveLoss","filedoc":"sourcefiles/NeuralPDE/src/pinns_pde_solve.jl","signature":"NeuralPDE.GradientScaleAdaptiveLoss(reweight_every; weight_change_inertia, pde_loss_weights, bc_loss_weights, additional_loss_weights)"}],"name":"GradientScaleAdaptiveLoss","title":"GradientScaleAdaptiveLoss","symbol_id":"NeuralPDE.GradientScaleAdaptiveLoss","public":true,"module_id":"NeuralPDE"},"tag":"documentation","children":[{"attributes":{},"tag":"md","children":[{"attributes":{},"tag":"p","children":["A way of adaptively reweighting the components of the loss function in the total sum such that BC_i loss weights are scaled by the exponential moving average of max(|∇pde_loss|)/mean(|∇bc_i_loss|) )"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["reweight_every"],"type":"node"},": how often to reweight the BC loss functions, measured in iterations.  reweighting is somewhat expensive since it involves evaluating the gradient of each component loss function,"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["weight_change_inertia"],"type":"node"},": a real number that represents the inertia of the exponential moving average of the BC weight changes,"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["pde_loss_weights"],"type":"node"},": either a scalar (which will be broadcast) or vector the size of the number of PDE equations, which describes the weight the respective PDE loss has in the full loss sum,"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["bc_loss_weights"],"type":"node"},": either a scalar (which will be broadcast) or vector the size of the number of BC equations, which describes the initial weight the respective BC loss has in the full loss sum,"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["additional_loss_weights"],"type":"node"},": a scalar which describes the weight the additional loss function has in the full loss sum, this is currently not adaptive and will be constant with this adaptive loss,"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["from paper Understanding and mitigating gradient pathologies in physics-informed neural networks Sifan Wang, Yujun Teng, Paris Perdikaris https://arxiv.org/abs/2001.04536v1 with code reference https://github.com/PredictiveIntelligenceLab/GradientPathologiesPINNs"],"type":"node"}],"type":"node"}],"type":"node"}