{"attributes":{"kind":"struct","backlinks":[{"tag":"sourcefile","title":"NeuralPDE/src/pinns_pde_solve.jl","docid":"sourcefiles/NeuralPDE/src/pinns_pde_solve.jl"},{"tag":"sourcefile","title":"NeuralPDE/src/NeuralPDE.jl","docid":"sourcefiles/NeuralPDE/src/NeuralPDE.jl"}],"methods":[{"line":332,"file":"/Users/lorenz/.julia/packages/NeuralPDE/y7uHG/src/pinns_pde_solve.jl","method_id":"NeuralPDE.MiniMaxAdaptiveLoss_1","symbol_id":"NeuralPDE.MiniMaxAdaptiveLoss","filedoc":"sourcefiles/NeuralPDE/src/pinns_pde_solve.jl","signature":"NeuralPDE.MiniMaxAdaptiveLoss(; reweight_every, pde_max_optimiser, bc_max_optimiser, pde_loss_weights, bc_loss_weights, additional_loss_weights)"},{"line":332,"file":"/Users/lorenz/.julia/packages/NeuralPDE/y7uHG/src/pinns_pde_solve.jl","method_id":"NeuralPDE.MiniMaxAdaptiveLoss_2","symbol_id":"NeuralPDE.MiniMaxAdaptiveLoss","filedoc":"sourcefiles/NeuralPDE/src/pinns_pde_solve.jl","signature":"NeuralPDE.MiniMaxAdaptiveLoss(reweight_every; pde_max_optimiser, bc_max_optimiser, pde_loss_weights, bc_loss_weights, additional_loss_weights)"}],"name":"MiniMaxAdaptiveLoss","title":"MiniMaxAdaptiveLoss","symbol_id":"NeuralPDE.MiniMaxAdaptiveLoss","public":true,"module_id":"NeuralPDE"},"tag":"documentation","children":[{"attributes":{},"tag":"md","children":[{"attributes":{},"tag":"p","children":["A way of adaptively reweighting the components of the loss function in the total sum such that the loss weights are maximized by an internal optimiser, which leads to a behavior where loss functions that have not been satisfied get a greater weight,"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["reweight_every"],"type":"node"},": how often to reweight the PDE and BC loss functions, measured in iterations.  reweighting is cheap since it re-uses the value of loss functions generated during the main optimisation loop,"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["pde_max_optimiser"],"type":"node"},": a Flux.Optimise.AbstractOptimiser that is used internally to maximize the weights of the PDE loss functions,"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["bc_max_optimiser"],"type":"node"},": a Flux.Optimise.AbstractOptimiser that is used internally to maximize the weights of the BC loss functions,"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["pde_loss_weights"],"type":"node"},": either a scalar (which will be broadcast) or vector the size of the number of PDE equations, which describes the initial weight the respective PDE loss has in the full loss sum,"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["bc_loss_weights"],"type":"node"},": either a scalar (which will be broadcast) or vector the size of the number of BC equations, which describes the initial weight the respective BC loss has in the full loss sum,"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["additional_loss_weights"],"type":"node"},": a scalar which describes the weight the additional loss function has in the full loss sum, this is currently not adaptive and will be constant with this adaptive loss,"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["from paper Self-Adaptive Physics-Informed Neural Networks using a Soft Attention Mechanism Levi McClenny, Ulisses Braga-Neto https://arxiv.org/abs/2009.04544"],"type":"node"}],"type":"node"}],"type":"node"}