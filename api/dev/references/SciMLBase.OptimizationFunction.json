{"attributes":{"kind":"struct","backlinks":[{"tag":"sourcefile","title":"SciMLBase/src/problems/basic_problems.jl","docid":"sourcefiles/SciMLBase/src/problems/basic_problems.jl"},{"tag":"sourcefile","title":"SciMLBase/src/scimlfunctions.jl","docid":"sourcefiles/SciMLBase/src/scimlfunctions.jl"},{"tag":"sourcefile","title":"SciMLBase/src/SciMLBase.jl","docid":"sourcefiles/SciMLBase/src/SciMLBase.jl"}],"methods":[{"line":2537,"file":"/home/runner/.julia/packages/SciMLBase/dYFnI/src/scimlfunctions.jl","method_id":"SciMLBase.OptimizationFunction_1","symbol_id":"SciMLBase.OptimizationFunction","filedoc":"sourcefiles/SciMLBase/src/scimlfunctions.jl","signature":"SciMLBase.OptimizationFunction(args...; kwargs...)"}],"name":"OptimizationFunction","title":"OptimizationFunction","symbol_id":"SciMLBase.OptimizationFunction","public":true,"module_id":"SciMLBase"},"tag":"documentation","children":[{"attributes":{},"tag":"md","children":[{"attributes":{},"tag":"p","children":["OptimizationFunction <: AbstractOptimizationFunction"],"type":"node"},{"attributes":{},"tag":"p","children":["A representation of an optimization of an objective function ",{"attributes":{},"tag":"code","children":["f"],"type":"node"},", defined by:"],"type":"node"},{"attributes":{},"tag":"mathblock","children":["min_{u} f(u,p)"],"type":"node"},{"attributes":{},"tag":"p","children":["and all of its related functions, such as the gradient of ",{"attributes":{},"tag":"code","children":["f"],"type":"node"},", its Hessian, and more. For all cases, ",{"attributes":{},"tag":"code","children":["u"],"type":"node"}," is the state and ",{"attributes":{},"tag":"code","children":["p"],"type":"node"}," are the parameters."],"type":"node"},{"attributes":{},"tag":"h2","children":["Constructor"],"type":"node"},{"attributes":{},"tag":"p","children":["OptimizationFunction(f,adtype::AbstractADType=NoAD(); grad=nothing,hess=nothing,hv=nothing, cons=nothing, cons_j=nothing,cons_h=nothing, hess_prototype=nothing,cons_jac_prototype=nothing, cons_hess_prototype = nothing, syms = nothing, hess_colorvec = nothing, cons_jac_colorvec = nothing, cons_hess_colorvec = nothing)"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["adtype"],"type":"node"},": see the section \"Defining Optimization Functions via AD\""],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["grad(G,u,p)"],"type":"node"}," or ",{"attributes":{},"tag":"code","children":["G=grad(u,p)"],"type":"node"},": the gradient of ",{"attributes":{},"tag":"code","children":["f"],"type":"node"}," with respect to ",{"attributes":{},"tag":"code","children":["u"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["hess(H,u,p)"],"type":"node"}," or ",{"attributes":{},"tag":"code","children":["H=hess(u,p)"],"type":"node"},": the Hessian of ",{"attributes":{},"tag":"code","children":["f"],"type":"node"}," with respect to ",{"attributes":{},"tag":"code","children":["u"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["hv(Hv,u,v,p)"],"type":"node"}," or ",{"attributes":{},"tag":"code","children":["Hv=hv(u,v,p)"],"type":"node"},": the Hessian-vector product ",{"attributes":{},"tag":"math","children":["rac{d^2 f}{du^2} v"],"type":"node"},"."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["cons(res,x,p)"],"type":"node"}," or ",{"attributes":{},"tag":"code","children":["res=cons(x,p)"],"type":"node"},": the equality constraints vector, where the constraints are satisfied when ",{"attributes":{},"tag":"code","children":["res = 0"],"type":"node"},"."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["cons_j(res,x,p)"],"type":"node"}," or ",{"attributes":{},"tag":"code","children":["res=cons_j(x,p)"],"type":"node"},": the Jacobian of the equality constraints."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["cons_h(res,x,p)"],"type":"node"}," or ",{"attributes":{},"tag":"code","children":["res=cons_h(x,p)"],"type":"node"},": the Hessian of the equality constratins, provided as and array of Hessians with ",{"attributes":{},"tag":"code","children":["res[i]"],"type":"node"}," being the Hessian with respect to the ",{"attributes":{},"tag":"code","children":["i"],"type":"node"},"th output on ",{"attributes":{},"tag":"code","children":["cons"],"type":"node"},"."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["paramjac(pJ,u,p)"],"type":"node"},": returns the parameter Jacobian ",{"attributes":{},"tag":"math","children":["rac{df}{dp}"],"type":"node"},"."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["hess_prototype"],"type":"node"},": a prototype matrix matching the type that matches the Hessian. For example, if the Hessian is tridiagonal, then an appropriately sized ",{"attributes":{},"tag":"code","children":["Hessian"],"type":"node"}," matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a ",{"attributes":{},"tag":"code","children":["SparseMatrixCSC"],"type":"node"}," with a correct sparsity pattern for the Hessian. The default is ",{"attributes":{},"tag":"code","children":["nothing"],"type":"node"},", which means a dense Hessian."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["cons_jac_prototype"],"type":"node"},": a prototype matrix matching the type that matches the constraint Jacobian. The default is ",{"attributes":{},"tag":"code","children":["nothing"],"type":"node"},", which means a dense constraint Jacobian."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["cons_hess_prototype"],"type":"node"},": a prototype matrix matching the type that matches the constraint Hessian. This is defined as an array of matrices, where ",{"attributes":{},"tag":"code","children":["hess[i]"],"type":"node"}," is the Hessian w.r.t. the ",{"attributes":{},"tag":"code","children":["i"],"type":"node"},"th output. For example, if the Hessian is sparse, then ",{"attributes":{},"tag":"code","children":["hess"],"type":"node"}," is a ",{"attributes":{},"tag":"code","children":["Vector{SparseMatrixCSC}"],"type":"node"},". The default is ",{"attributes":{},"tag":"code","children":["nothing"],"type":"node"},", which means a dense constraint Hessian."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["syms"],"type":"node"},": the symbol names for the elements of the equation. This should match ",{"attributes":{},"tag":"code","children":["u0"],"type":"node"}," in size. For example, if ",{"attributes":{},"tag":"code","children":["u = [0.0,1.0]"],"type":"node"}," and ",{"attributes":{},"tag":"code","children":["syms = [:x, :y]"],"type":"node"},", this will apply a canonical naming to the values, allowing ",{"attributes":{},"tag":"code","children":["sol[:x]"],"type":"node"}," in the solution and automatically naming values in plots."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["hess_colorvec"],"type":"node"},": a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the ",{"attributes":{},"tag":"code","children":["hess_prototype"],"type":"node"},". This specializes the Hessian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to ",{"attributes":{},"tag":"code","children":["nothing"],"type":"node"},", which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["cons_jac_colorvec"],"type":"node"},": a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the ",{"attributes":{},"tag":"code","children":["cons_jac_prototype"],"type":"node"},"."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["cons_hess_colorvec"],"type":"node"},": an array of color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the ",{"attributes":{},"tag":"code","children":["cons_hess_prototype"],"type":"node"},"."],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"h2","children":["Defining Optimization Functions Via AD"],"type":"node"},{"attributes":{},"tag":"p","children":["While using the keyword arguments gives the user control over defining all of the possible functions, the simplest way to handle the generation of an ",{"attributes":{},"tag":"code","children":["OptimizationFunction"],"type":"node"}," is by specifying an AD type. By doing so, this will automatically fill in all of the extra functions. For example,"],"type":"node"},{"attributes":{"lang":"julia"},"tag":"codeblock","children":[{"attributes":{},"tag":"julia","children":[{"attributes":{},"tag":"CALL","children":[{"attributes":{"reftype":"symbol","document_id":"references/SciMLBase.OptimizationFunction"},"tag":"reference","children":["OptimizationFunction"],"type":"node"},{"attributes":{},"tag":"LPAREN","children":["("],"type":"node"},{"attributes":{},"tag":"IDENTIFIER","children":["f"],"type":"node"},{"attributes":{},"tag":"COMMA","children":[","],"type":"node"},{"attributes":{},"tag":"CALL","children":[{"attributes":{},"tag":"IDENTIFIER","children":["AutoZygote"],"type":"node"},{"attributes":{},"tag":"LPAREN","children":["("],"type":"node"},{"attributes":{},"tag":"RPAREN","children":[")"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"RPAREN","children":[")"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["will use ",{"attributes":{"href":"https://github.com/FluxML/Zygote.jl","title":""},"tag":"a","children":["Zygote.jl"],"type":"node"}," to define all of the necessary functions. Note that if any functions are defined directly, the auto-AD definition does not overwrite the user's choice."],"type":"node"},{"attributes":{},"tag":"p","children":["Each of the AD-based constructors are documented separately via their own dispatches."],"type":"node"},{"attributes":{},"tag":"h2","children":["iip: In-Place vs Out-Of-Place"],"type":"node"},{"attributes":{},"tag":"p","children":["For more details on this argument, see the ODEFunction documentation."],"type":"node"},{"attributes":{},"tag":"h2","children":["recompile: Controlling Compilation and Specialization"],"type":"node"},{"attributes":{},"tag":"p","children":["For more details on this argument, see the ODEFunction documentation."],"type":"node"},{"attributes":{},"tag":"h2","children":["Fields"],"type":"node"},{"attributes":{},"tag":"p","children":["The fields of the OptimizationFunction type directly match the names of the inputs."],"type":"node"}],"type":"node"}],"type":"node"}