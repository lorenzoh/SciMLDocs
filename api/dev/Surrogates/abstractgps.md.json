{"attributes":{"backlinks":[],"path":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/docs/src/abstractgps.md","title":"Gaussian Process Surrogate Tutorial"},"tag":"document","children":[{"attributes":{},"tag":"md","children":[{"attributes":{},"tag":"h1","children":["Gaussian Process Surrogate Tutorial"],"type":"node"},{"attributes":{"class":"note"},"tag":"admonition","children":[{"attributes":{},"tag":"admonitiontitle","children":["Note"],"type":"node"},{"attributes":{},"tag":"admonitionbody","children":[{"attributes":{},"tag":"p","children":["This surrogate requires the 'SurrogatesAbstractGPs' module which can be added by inputting \"]add SurrogatesAbstractGPs\" from the Julia command line."],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["Gaussian Process regression in Surrogates.jl is implemented as a simple wrapper around the ",{"attributes":{"href":"https://github.com/JuliaGaussianProcesses/AbstractGPs.jl","title":""},"tag":"a","children":["AbstractGPs.jl"],"type":"node"}," package. AbstractGPs comes with a variety of covariance functions (kernels). See ",{"attributes":{"href":"https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/","title":""},"tag":"a","children":["KernelFunctions.jl"],"type":"node"}," for examples."],"type":"node"},{"attributes":{"class":"tip"},"tag":"admonition","children":[{"attributes":{},"tag":"admonitiontitle","children":["Tip"],"type":"node"},{"attributes":{},"tag":"admonitionbody","children":[{"attributes":{},"tag":"p","children":["The examples below demonstrate the use of AbstractGPs with out-of-the-box settings without hyperparameter optimization (i.e. without changing parameters like lengthscale, signal variance and noise variance.) Beyond hyperparameter optimization, careful initialization of hyperparameters and priors on the parameters is required for this surrogate to work properly. For more details on how to fit GPs in practice, check out ",{"attributes":{"href":"https://infallible-thompson-49de36.netlify.app/","title":""},"tag":"a","children":["A Practical Guide to Gaussian Processes"],"type":"node"},"."],"type":"node"},{"attributes":{},"tag":"p","children":["Also see this ",{"attributes":{"href":"https://juliagaussianprocesses.github.io/AbstractGPs.jl/stable/examples/1-mauna-loa/#Hyperparameter-Optimization","title":""},"tag":"a","children":["example"],"type":"node"}," to understand hyperparameter optimization with AbstractGPs."],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"h2","children":["1D Example"],"type":"node"},{"attributes":{},"tag":"p","children":["In the example below, the 'gp_surrogate' assignment code can be commented / uncommented to see how the different kernels influence the predictions."],"type":"node"},{"attributes":{"lang":"@example gp_tutorial1d"},"tag":"codeblock","children":["using Surrogates\nusing Plots\ndefault()\nusing AbstractGPs #required to access different types of kernels\nusing SurrogatesAbstractGPs\n\nf(x) = (6 * x - 2)^2 * sin(12 * x - 4)\nn_samples = 4\nlower_bound = 0.0\nupper_bound = 1.0\nxs = lower_bound:0.001:upper_bound\nx = sample(n_samples, lower_bound, upper_bound, SobolSample())\ny = f.(x)\n#gp_surrogate = AbstractGPSurrogate(x,y, gp=GP(SqExponentialKernel()), Σy=0.05) #example of Squared Exponential Kernel\n#gp_surrogate = AbstractGPSurrogate(x,y, gp=GP(MaternKernel()), Σy=0.05) #example of MaternKernel\ngp_surrogate = AbstractGPSurrogate(x,y, gp=GP(PolynomialKernel(; c=2.0, degree=5)), Σy=0.25)\nplot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lower_bound, upper_bound), ylims=(-7, 17), legend=:top)\nplot!(xs, f.(xs), label=\"True function\", legend=:top)\nplot!(0:0.001:1, gp_surrogate.gp_posterior; label=\"Posterior\", ribbon_scale=2)\n"],"type":"node"},{"attributes":{},"tag":"h2","children":["Optimization Example"],"type":"node"},{"attributes":{},"tag":"p","children":["This example shows the use of AbstractGP Surrogates to find the minima of a function:"],"type":"node"},{"attributes":{"lang":"@example abstractgps_tutorial_optimization"},"tag":"codeblock","children":["using Surrogates\nusing Plots\nusing AbstractGPs\nusing SurrogatesAbstractGPs\n\nf(x) = (x-2)^2\nn_samples = 4\nlower_bound = 0.0\nupper_bound = 4.0\nxs = lower_bound:0.1:upper_bound\nx = sample(n_samples, lower_bound, upper_bound, SobolSample())\ny = f.(x)\ngp_surrogate = AbstractGPSurrogate(x,y)\n@show surrogate_optimize(f, SRBF(), lower_bound, upper_bound, gp_surrogate, SobolSample())\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Plotting the function and the sampled points:"],"type":"node"},{"attributes":{"lang":"@example abstractgps_tutorial_optimization"},"tag":"codeblock","children":["scatter(gp_surrogate.x, gp_surrogate.y, label=\"Sampled points\", ylims=(-1.0, 5.0), legend=:top)\nplot!(xs, gp_surrogate.(xs), label=\"Surrogate function\", ribbon=p->std_error_at_point(gp_surrogate, p), legend=:top)\nplot!(xs, f.(xs), label=\"True function\", legend=:top)\n"],"type":"node"},{"attributes":{},"tag":"h2","children":["ND Example"],"type":"node"},{"attributes":{"lang":"@example abstractgps_tutorialnd"},"tag":"codeblock","children":["using Plots\ndefault(c=:matter, legend=false, xlabel=\"x\", ylabel=\"y\")\nusing Surrogates\nusing AbstractGPs\nusing SurrogatesAbstractGPs\n\n\nhypot_func = z -> 3*hypot(z...)+1\nn_samples = 50\nlower_bound = [-1.0, -1.0]\nupper_bound = [1.0, 1.0]\n\nxys = sample(n_samples, lower_bound, upper_bound, SobolSample())\nzs = hypot_func.(xys);\n\nx, y = -2:2, -2:2 \np1 = surface(x, y, (x1,x2) -> hypot_func((x1,x2))) \nxs = [xy[1] for xy in xys] \nys = [xy[2] for xy in xys] \nscatter!(xs, ys, zs) \np2 = contour(x, y, (x1,x2) -> hypot_func((x1,x2)))\nscatter!(xs, ys)\nplot(p1, p2, title=\"True function\")\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Now let's see how our surrogate performs:"],"type":"node"},{"attributes":{"lang":"@example abstractgps_tutorialnd"},"tag":"codeblock","children":["gp_surrogate = AbstractGPSurrogate(xys, zs)\np1 = surface(x, y, (x, y) -> gp_surrogate([x y]))\nscatter!(xs, ys, zs, marker_z=zs)\np2 = contour(x, y, (x, y) -> gp_surrogate([x y]))\nscatter!(xs, ys, marker_z=zs)\nplot(p1, p2, title=\"Surrogate\")\n"],"type":"node"},{"attributes":{"lang":"@example abstractgps_tutorialnd"},"tag":"codeblock","children":["@show gp_surrogate((0.2,0.2))\n"],"type":"node"},{"attributes":{"lang":"@example abstractgps_tutorialnd"},"tag":"codeblock","children":["@show hypot_func((0.2,0.2))\n"],"type":"node"},{"attributes":{},"tag":"p","children":["And this is our log marginal posterior predictive probability:"],"type":"node"},{"attributes":{"lang":"@example abstractgps_tutorialnd"},"tag":"codeblock","children":["@show logpdf_surrogate(gp_surrogate)\n"],"type":"node"}],"type":"node"}],"type":"node"}