{"attributes":{"backlinks":[],"path":"/Users/lorenz/.julia/packages/Surrogates/zwNvG/docs/src/neural.md","title":"Neural network tutorial"},"tag":"document","children":[{"attributes":{},"tag":"md","children":[{"attributes":{},"tag":"h1","children":["Neural network tutorial"],"type":"node"},{"attributes":{"class":"note"},"tag":"admonition","children":[{"attributes":{},"tag":"admonitiontitle","children":["Note"],"type":"node"},{"attributes":{},"tag":"admonitionbody","children":[{"attributes":{},"tag":"p","children":["This surrogate requires the 'SurrogatesFlux' module which can be added by inputting \"]add SurrogatesFlux\" from the Julia command line."],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["It's possible to define a neural network as a surrogate, using Flux. This is useful because we can call optimization methods on it."],"type":"node"},{"attributes":{},"tag":"p","children":["First of all we will define the ",{"attributes":{},"tag":"code","children":["Schaffer"],"type":"node"}," function we are going to build surrogate for."],"type":"node"},{"attributes":{"lang":"@example Neural_surrogate"},"tag":"codeblock","children":["using Plots\ndefault(c=:matter, legend=false, xlabel=\"x\", ylabel=\"y\") # hide\nusing Surrogates\nusing Flux\nusing SurrogatesFlux\n\nfunction schaffer(x)\n    x1=x[1]\n    x2=x[2]\n    fact1 = x1 ^2;\n    fact2 = x2 ^2;\n    y = fact1 + fact2;\nend\n"],"type":"node"},{"attributes":{},"tag":"h2","children":["Sampling"],"type":"node"},{"attributes":{},"tag":"p","children":["Let's define our bounds, this time we are working in two dimensions. In particular we want our first dimension ",{"attributes":{},"tag":"code","children":["x"],"type":"node"}," to have bounds ",{"attributes":{},"tag":"code","children":["0, 8"],"type":"node"},", and ",{"attributes":{},"tag":"code","children":["0, 8"],"type":"node"}," for the second dimension. We are taking 60 samples of the space using Sobol Sequences. We then evaluate our function on all of the sampling points."],"type":"node"},{"attributes":{"lang":"@example Neural_surrogate"},"tag":"codeblock","children":["n_samples = 60\nlower_bound = [0.0, 0.0]\nupper_bound = [8.0, 8.0]\n\nxys = sample(n_samples, lower_bound, upper_bound, SobolSample())\nzs = schaffer.(xys);\n"],"type":"node"},{"attributes":{"lang":"@example Neural_surrogate"},"tag":"codeblock","children":["x, y = 0:8, 0:8 # hide\np1 = surface(x, y, (x1,x2) -> schaffer((x1,x2))) # hide\nxs = [xy[1] for xy in xys] # hide\nys = [xy[2] for xy in xys] # hide\nscatter!(xs, ys, zs) # hide\np2 = contour(x, y, (x1,x2) -> schaffer((x1,x2))) # hide\nscatter!(xs, ys) # hide\nplot(p1, p2, title=\"True function\") # hide\n"],"type":"node"},{"attributes":{},"tag":"h2","children":["Building a surrogate"],"type":"node"},{"attributes":{},"tag":"p","children":["You can specify your own model, optimization function, loss functions and epochs. As always, getting the model right is hardest thing."],"type":"node"},{"attributes":{"lang":"@example Neural_surrogate"},"tag":"codeblock","children":["model1 = Chain(\n  Dense(2, 5, σ),\n  Dense(5,2,σ),\n  Dense(2, 1)\n)\nneural = NeuralSurrogate(xys, zs, lower_bound, upper_bound, model = model1, n_echos = 10)\n"],"type":"node"},{"attributes":{},"tag":"h2","children":["Optimization"],"type":"node"},{"attributes":{},"tag":"p","children":["We can now call an optimization function on the neural network:"],"type":"node"},{"attributes":{"lang":"@example Neural_surrogate"},"tag":"codeblock","children":["surrogate_optimize(schaffer, SRBF(), lower_bound, upper_bound, neural, SobolSample(), maxiters=20, num_new_samples=10)\n"],"type":"node"}],"type":"node"}],"type":"node"}